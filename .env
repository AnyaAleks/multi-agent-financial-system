# Создаем .env файл
cat > .env << 'EOF'
# AI Configuration
AI_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:latest

# System
ENVIRONMENT=development
LOG_LEVEL=INFO

# Agents
CREWAI_MAX_RPM=30
CREWAI_TEMPERATURE=0.1

# Memory (пока без Redis для простоты)
REDIS_URL=redis://localhost:6379
REDIS_TTL=1800

# Performance
PARALLEL_EXECUTION=true
MAX_WORKERS=2

# Dashboard
STREAMLIT_SERVER_PORT=8501
STREAMLIT_SERVER_ADDRESS=0.0.0.0

# RAG
EMBEDDING_MODEL=all-MiniLM-L6-v2
VECTOR_STORE_TYPE=chroma
CHUNK_SIZE=512
CHUNK_OVERLAP=50
EOF